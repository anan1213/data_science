{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test.csv', 'additionalTrainData.csv', 'TestAdditionalFeatures.csv', 'output', '.ipynb_checkpoints', 'train.csv', 'release_dates_per_country.csv', 'trainV3.csv', 'TrainAdditionalFeatures.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from funcs import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(os.listdir('../data/movie'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/movie/train.csv')\n",
    "test = pd.read_csv('../data/movie/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['logRevenue'] = np.log1p(train['revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since only last two digits of year are provided, this is the correct way of getting the year.\n",
    "train[['release_month','release_day','release_year']]=train['release_date'].str.split('/',expand=True).replace(np.nan, -1).astype(int)\n",
    "# Some rows have 4 digits of year instead of 2, that's why I am applying (train['release_year'] < 100) this condition\n",
    "train.loc[ (train['release_year'] <= 19) & (train['release_year'] < 100), \"release_year\"] += 2000\n",
    "train.loc[ (train['release_year'] > 19)  & (train['release_year'] < 100), \"release_year\"] += 1900\n",
    "\n",
    "releaseDate = pd.to_datetime(train['release_date']) \n",
    "train['release_dayofweek'] = releaseDate.dt.dayofweek\n",
    "train['release_quarter'] = releaseDate.dt.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meanRevenueByYear'] = train.groupby(\"release_year\")[\"revenue\"].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meanRevenueByDayOfWeek'] = train.groupby(\"release_dayofweek\")[\"revenue\"].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meanruntimeByYear'] = train.groupby(\"release_year\")[\"runtime\"].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meanPopularityByYear'] = train.groupby(\"release_year\")[\"popularity\"].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meanBudgetByYear'] = train.groupby(\"release_year\")[\"budget\"].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary(s):\n",
    "    try:\n",
    "        d = eval(s)\n",
    "    except:\n",
    "        d = {}\n",
    "    return d\n",
    "train = train\n",
    "train['genres'] = train['genres'].map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n",
    "genres = train.genres.str.get_dummies(sep=',')\n",
    "train = pd.concat([train, genres], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test\n",
    "test['genres'] = test['genres'].map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n",
    "genres = test.genres.str.get_dummies(sep=',')\n",
    "test = pd.concat([test, genres], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Rumored</td>\n",
       "      <td>273644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>Rumored</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>Rumored</td>\n",
       "      <td>13418091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>Rumored</td>\n",
       "      <td>229000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       status   revenue\n",
       "609   Rumored    273644\n",
       "1007  Rumored        60\n",
       "1216  Rumored  13418091\n",
       "1618  Rumored    229000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['status'] == \"Rumored\"][['status','revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['has_homepage'] = 1\n",
    "train.loc[pd.isnull(train['homepage']) ,\"has_homepage\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['isTaglineNA'] = 0\n",
    "train.loc[pd.isnull(train['tagline']) ,\"isTaglineNA\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['isTaglineNA'] = 0\n",
    "train.loc[pd.isnull(train['tagline']) ,\"isTaglineNA\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['isOriginalLanguageEng'] = 0 \n",
    "train.loc[ train['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAdditionalFeatures = pd.read_csv('../data/movie/TrainAdditionalFeatures.csv')\n",
    "testAdditionalFeatures = pd.read_csv('../data/movie/TestAdditionalFeatures.csv')\n",
    "\n",
    "train = pd.merge(train, trainAdditionalFeatures, how='left', on=['imdb_id'])\n",
    "test = pd.merge(test, testAdditionalFeatures, how='left', on=['imdb_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rating'] = train['rating'].fillna(1.5)\n",
    "train['totalVotes'] = train['totalVotes'].fillna(6)\n",
    "\n",
    "test['rating'] = test['rating'].fillna(1.5)\n",
    "test['totalVotes'] = test['totalVotes'].fillna(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meanRevenueByRating'] = train.groupby(\"rating\")[\"revenue\"].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meanRevenueByTotalVotes'] = train.groupby(\"totalVotes\")[\"revenue\"].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meantotalVotesByYear'] = train.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meanTotalVotesByRating'] = train.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['budget','rating','totalVotes','popularity','runtime','release_year','release_month','release_dayofweek','revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:00<00:01,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Keywords', 'belongs_to_collection', 'budget', 'cast', 'crew', 'genres',\n",
      "       'homepage', 'id', 'imdb_id', 'original_language', 'original_title',\n",
      "       'overview', 'popularity', 'popularity2', 'poster_path',\n",
      "       'production_companies', 'production_countries', 'rating',\n",
      "       'release_date', 'revenue', 'runtime', 'spoken_languages', 'status',\n",
      "       'tagline', 'title', 'totalVotes'],\n",
      "      dtype='object')\n",
      "(5001, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:07<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "def prepare(df):\n",
    "    global json_cols\n",
    "    global train_dict\n",
    "\n",
    "    df[['release_month','release_day','release_year']]=df['release_date'].str.split('/',expand=True).replace(np.nan, 0).astype(int)\n",
    "    df['release_year'] = df['release_year']\n",
    "    df.loc[ (df['release_year'] <= 19) & (df['release_year'] < 100), \"release_year\"] += 2000\n",
    "    df.loc[ (df['release_year'] > 19)  & (df['release_year'] < 100), \"release_year\"] += 1900\n",
    "    \n",
    "    releaseDate = pd.to_datetime(df['release_date']) \n",
    "    df['release_dayofweek'] = releaseDate.dt.dayofweek \n",
    "    df['release_quarter'] = releaseDate.dt.quarter     \n",
    "    \n",
    "    rating_na = df.groupby([\"release_year\",\"original_language\"])['rating'].mean().reset_index()\n",
    "    df[df.rating.isna()]['rating'] = df.merge(rating_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
    "    vote_count_na = df.groupby([\"release_year\",\"original_language\"])['totalVotes'].mean().reset_index()\n",
    "    df[df.totalVotes.isna()]['totalVotes'] = df.merge(vote_count_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
    "    #df['rating'] = df['rating'].fillna(1.5)\n",
    "    #df['totalVotes'] = df['totalVotes'].fillna(6)\n",
    "    df['weightedRating'] = ( df['rating']*df['totalVotes'] + 6.367 * 1000 ) / ( df['totalVotes'] + 1000 )\n",
    "\n",
    "\n",
    "    df['originalBudget'] = df['budget']\n",
    "    df['inflationBudget'] = df['budget'] + df['budget']*1.8/100*(2018-df['release_year']) #Inflation simple formula\n",
    "    df['budget'] = np.log1p(df['budget']) \n",
    "    \n",
    "    \n",
    "    # Thanks to this Kernel for the next 7 features https://www.kaggle.com/artgor/eda-feature-engineering-and-model-interpretation\n",
    "    df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
    "    df['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
    "    df['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
    "    df['_collection_name'] = df['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(df['_collection_name'].fillna('')))\n",
    "    df['_collection_name'] = le.transform(df['_collection_name'].fillna('').astype(str))\n",
    "    df['_num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
    "    df['_num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n",
    "\n",
    "    \n",
    "    \n",
    "    df['_popularity_mean_year'] = df['popularity'] / df.groupby(\"release_year\")[\"popularity\"].transform('mean')\n",
    "    df['_budget_runtime_ratio'] = df['budget']/df['runtime'] \n",
    "    df['_budget_popularity_ratio'] = df['budget']/df['popularity']\n",
    "    df['_budget_year_ratio'] = df['budget']/(df['release_year']*df['release_year'])\n",
    "    df['_releaseYear_popularity_ratio'] = df['release_year']/df['popularity']\n",
    "    df['_releaseYear_popularity_ratio2'] = df['popularity']/df['release_year']\n",
    "\n",
    "    df['_popularity_totalVotes_ratio'] = df['totalVotes']/df['popularity']\n",
    "    df['_rating_popularity_ratio'] = df['rating']/df['popularity']\n",
    "    df['_rating_totalVotes_ratio'] = df['totalVotes']/df['rating']\n",
    "    df['_totalVotes_releaseYear_ratio'] = df['totalVotes']/df['release_year']\n",
    "    df['_budget_rating_ratio'] = df['budget']/df['rating']\n",
    "    df['_runtime_rating_ratio'] = df['runtime']/df['rating']\n",
    "    df['_budget_totalVotes_ratio'] = df['budget']/df['totalVotes']\n",
    "    \n",
    "    df['has_homepage'] = 1\n",
    "    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 0\n",
    "    \n",
    "    df['isbelongs_to_collectionNA'] = 0\n",
    "    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n",
    "    \n",
    "    df['isTaglineNA'] = 0\n",
    "    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n",
    "\n",
    "    df['isOriginalLanguageEng'] = 0 \n",
    "    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n",
    "    \n",
    "    df['isTitleDifferent'] = 1\n",
    "    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n",
    "\n",
    "    df['isMovieReleased'] = 1\n",
    "    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n",
    "\n",
    "    # get collection id\n",
    "    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n",
    "    \n",
    "    df['original_title_letter_count'] = df['original_title'].str.len() \n",
    "    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n",
    "\n",
    "\n",
    "    df['title_word_count'] = df['title'].str.split().str.len()\n",
    "    df['overview_word_count'] = df['overview'].str.split().str.len()\n",
    "    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n",
    "    \n",
    "    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n",
    "    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n",
    "    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n",
    "    df['crew_count'] = df['crew'].apply(lambda x : len(x))\n",
    "    \n",
    "\n",
    "    df['meanruntimeByYear'] = df.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n",
    "    df['meanPopularityByYear'] = df.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\n",
    "    df['meanBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('mean')\n",
    "    df['meantotalVotesByYear'] = df.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\n",
    "    df['meanTotalVotesByRating'] = df.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n",
    "    df['medianBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('median')\n",
    "\n",
    "    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n",
    "        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n",
    "        temp = df[col].str.get_dummies(sep=',')\n",
    "        df = pd.concat([df, temp], axis=1, sort=False)\n",
    "    df.drop(['genres_etc'], axis = 1, inplace = True)\n",
    "    \n",
    "    df = df.drop(['id', 'revenue','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n",
    "    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n",
    "    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n",
    "    ],axis=1)\n",
    "    \n",
    "    df.fillna(value=0.0, inplace = True) \n",
    "\n",
    "    return df\n",
    "train = pd.read_csv('../data/movie/train.csv')\n",
    "\n",
    "#power_six = train.id[train.budget > 1000][train.revenue < 100]\n",
    "\n",
    "#for k in power_six :\n",
    "#    train.loc[train['id'] == k,'revenue'] =  train.loc[train['id'] == k,'revenue'] * 1000000\n",
    "#Clean Datapower_six \n",
    " \n",
    "train.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\n",
    "train.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \n",
    "train.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\n",
    "train.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\n",
    "train.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \n",
    "train.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\n",
    "train.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\n",
    "train.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\n",
    "train.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\n",
    "train.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\n",
    "train.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\n",
    "train.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\n",
    "train.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \n",
    "train.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\n",
    "train.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \n",
    "train.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \n",
    "train.loc[train['id'] == 1542,'budget'] = 1              # All at Once\n",
    "train.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\n",
    "train.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\n",
    "train.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\n",
    "train.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\n",
    "train.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\n",
    "train.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\n",
    "train.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\n",
    "train.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\n",
    "train.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\n",
    "train.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\n",
    "train.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\n",
    "train.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\n",
    "train.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\n",
    "train.loc[train['id'] == 335,'budget'] = 2 \n",
    "train.loc[train['id'] == 348,'budget'] = 12\n",
    "train.loc[train['id'] == 470,'budget'] = 13000000 \n",
    "train.loc[train['id'] == 513,'budget'] = 1100000\n",
    "train.loc[train['id'] == 640,'budget'] = 6 \n",
    "train.loc[train['id'] == 696,'budget'] = 1\n",
    "train.loc[train['id'] == 797,'budget'] = 8000000 \n",
    "train.loc[train['id'] == 850,'budget'] = 1500000\n",
    "train.loc[train['id'] == 1199,'budget'] = 5 \n",
    "train.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\n",
    "train.loc[train['id'] == 1347,'budget'] = 1\n",
    "train.loc[train['id'] == 1755,'budget'] = 2\n",
    "train.loc[train['id'] == 1801,'budget'] = 5\n",
    "train.loc[train['id'] == 1918,'budget'] = 592 \n",
    "train.loc[train['id'] == 2033,'budget'] = 4\n",
    "train.loc[train['id'] == 2118,'budget'] = 344 \n",
    "train.loc[train['id'] == 2252,'budget'] = 130\n",
    "train.loc[train['id'] == 2256,'budget'] = 1 \n",
    "train.loc[train['id'] == 2696,'budget'] = 10000000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test = pd.read_csv('../data/movie/test.csv')\n",
    "\n",
    "#Clean Data\n",
    "test.loc[test['id'] == 6733,'budget'] = 5000000\n",
    "test.loc[test['id'] == 3889,'budget'] = 15000000\n",
    "test.loc[test['id'] == 6683,'budget'] = 50000000\n",
    "test.loc[test['id'] == 5704,'budget'] = 4300000\n",
    "test.loc[test['id'] == 6109,'budget'] = 281756\n",
    "test.loc[test['id'] == 7242,'budget'] = 10000000\n",
    "test.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\n",
    "test.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\n",
    "test.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\n",
    "test.loc[test['id'] == 3033,'budget'] = 250 \n",
    "test.loc[test['id'] == 3051,'budget'] = 50\n",
    "test.loc[test['id'] == 3084,'budget'] = 337\n",
    "test.loc[test['id'] == 3224,'budget'] = 4  \n",
    "test.loc[test['id'] == 3594,'budget'] = 25  \n",
    "test.loc[test['id'] == 3619,'budget'] = 500  \n",
    "test.loc[test['id'] == 3831,'budget'] = 3  \n",
    "test.loc[test['id'] == 3935,'budget'] = 500  \n",
    "test.loc[test['id'] == 4049,'budget'] = 995946 \n",
    "test.loc[test['id'] == 4424,'budget'] = 3  \n",
    "test.loc[test['id'] == 4460,'budget'] = 8  \n",
    "test.loc[test['id'] == 4555,'budget'] = 1200000 \n",
    "test.loc[test['id'] == 4624,'budget'] = 30 \n",
    "test.loc[test['id'] == 4645,'budget'] = 500 \n",
    "test.loc[test['id'] == 4709,'budget'] = 450 \n",
    "test.loc[test['id'] == 4839,'budget'] = 7\n",
    "test.loc[test['id'] == 3125,'budget'] = 25 \n",
    "test.loc[test['id'] == 3142,'budget'] = 1\n",
    "test.loc[test['id'] == 3201,'budget'] = 450\n",
    "test.loc[test['id'] == 3222,'budget'] = 6\n",
    "test.loc[test['id'] == 3545,'budget'] = 38\n",
    "test.loc[test['id'] == 3670,'budget'] = 18\n",
    "test.loc[test['id'] == 3792,'budget'] = 19\n",
    "test.loc[test['id'] == 3881,'budget'] = 7\n",
    "test.loc[test['id'] == 3969,'budget'] = 400\n",
    "test.loc[test['id'] == 4196,'budget'] = 6\n",
    "test.loc[test['id'] == 4221,'budget'] = 11\n",
    "test.loc[test['id'] == 4222,'budget'] = 500\n",
    "test.loc[test['id'] == 4285,'budget'] = 11\n",
    "test.loc[test['id'] == 4319,'budget'] = 1\n",
    "test.loc[test['id'] == 4639,'budget'] = 10\n",
    "test.loc[test['id'] == 4719,'budget'] = 45\n",
    "test.loc[test['id'] == 4822,'budget'] = 22\n",
    "test.loc[test['id'] == 4829,'budget'] = 20\n",
    "test.loc[test['id'] == 4969,'budget'] = 20\n",
    "test.loc[test['id'] == 5021,'budget'] = 40 \n",
    "test.loc[test['id'] == 5035,'budget'] = 1 \n",
    "test.loc[test['id'] == 5063,'budget'] = 14 \n",
    "test.loc[test['id'] == 5119,'budget'] = 2 \n",
    "test.loc[test['id'] == 5214,'budget'] = 30 \n",
    "test.loc[test['id'] == 5221,'budget'] = 50 \n",
    "test.loc[test['id'] == 4903,'budget'] = 15\n",
    "test.loc[test['id'] == 4983,'budget'] = 3\n",
    "test.loc[test['id'] == 5102,'budget'] = 28\n",
    "test.loc[test['id'] == 5217,'budget'] = 75\n",
    "test.loc[test['id'] == 5224,'budget'] = 3 \n",
    "test.loc[test['id'] == 5469,'budget'] = 20 \n",
    "test.loc[test['id'] == 5840,'budget'] = 1 \n",
    "test.loc[test['id'] == 5960,'budget'] = 30\n",
    "test.loc[test['id'] == 6506,'budget'] = 11 \n",
    "test.loc[test['id'] == 6553,'budget'] = 280\n",
    "test.loc[test['id'] == 6561,'budget'] = 7\n",
    "test.loc[test['id'] == 6582,'budget'] = 218\n",
    "test.loc[test['id'] == 6638,'budget'] = 5\n",
    "test.loc[test['id'] == 6749,'budget'] = 8 \n",
    "test.loc[test['id'] == 6759,'budget'] = 50 \n",
    "test.loc[test['id'] == 6856,'budget'] = 10\n",
    "test.loc[test['id'] == 6858,'budget'] =  100\n",
    "test.loc[test['id'] == 6876,'budget'] =  250\n",
    "test.loc[test['id'] == 6972,'budget'] = 1\n",
    "test.loc[test['id'] == 7079,'budget'] = 8000000\n",
    "test.loc[test['id'] == 7150,'budget'] = 118\n",
    "test.loc[test['id'] == 6506,'budget'] = 118\n",
    "test.loc[test['id'] == 7225,'budget'] = 6\n",
    "test.loc[test['id'] == 7231,'budget'] = 85\n",
    "test.loc[test['id'] == 5222,'budget'] = 5\n",
    "test.loc[test['id'] == 5322,'budget'] = 90\n",
    "test.loc[test['id'] == 5350,'budget'] = 70\n",
    "test.loc[test['id'] == 5378,'budget'] = 10\n",
    "test.loc[test['id'] == 5545,'budget'] = 80\n",
    "test.loc[test['id'] == 5810,'budget'] = 8\n",
    "test.loc[test['id'] == 5926,'budget'] = 300\n",
    "test.loc[test['id'] == 5927,'budget'] = 4\n",
    "test.loc[test['id'] == 5986,'budget'] = 1\n",
    "test.loc[test['id'] == 6053,'budget'] = 20\n",
    "test.loc[test['id'] == 6104,'budget'] = 1\n",
    "test.loc[test['id'] == 6130,'budget'] = 30\n",
    "test.loc[test['id'] == 6301,'budget'] = 150\n",
    "test.loc[test['id'] == 6276,'budget'] = 100\n",
    "test.loc[test['id'] == 6473,'budget'] = 100\n",
    "test.loc[test['id'] == 6842,'budget'] = 30\n",
    "\n",
    "\n",
    "test['revenue'] = np.nan\n",
    "\n",
    "# features from https://www.kaggle.com/kamalchhirang/eda-simple-feature-engineering-external-data\n",
    "train = pd.merge(train, pd.read_csv('../data/movie/TrainAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n",
    "test = pd.merge(test, pd.read_csv('../data/movie/TestAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n",
    "\n",
    "additionalTrainData = pd.read_csv('../data/movie/additionalTrainData.csv')\n",
    "additionalTrainData['release_date'] = additionalTrainData['release_date'].astype('str')\n",
    "additionalTrainData['release_date'] = additionalTrainData['release_date'].str.replace('-', '/')\n",
    "train = pd.concat([train, additionalTrainData])\n",
    "\n",
    "#train = pd.merge(train, additionalTrainData, how='left', on=['imdb_id'],axis=1)\n",
    "print(train.columns)\n",
    "print(train.shape)\n",
    "train['revenue'] = np.log1p(train['revenue'])\n",
    "y = train['revenue'].values\n",
    "\n",
    "json_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n",
    "\n",
    "def get_dictionary(s):\n",
    "    try:\n",
    "        d = eval(s)\n",
    "    except:\n",
    "        d = {}\n",
    "    return d\n",
    "\n",
    "for col in tqdm(json_cols + ['belongs_to_collection']) :\n",
    "    train[col] = train[col].apply(lambda x : get_dictionary(x))\n",
    "    test[col] = test[col].apply(lambda x : get_dictionary(x))\n",
    "    \n",
    "def get_json_dict(df) :\n",
    "    global json_cols\n",
    "    result = dict()\n",
    "    for e_col in json_cols :\n",
    "        d = dict()\n",
    "        rows = df[e_col].values\n",
    "        for row in rows :\n",
    "            if row is None : continue\n",
    "            for i in row :\n",
    "                if i['name'] not in d :\n",
    "                    d[i['name']] = 0\n",
    "                d[i['name']] += 1\n",
    "        result[e_col] = d\n",
    "    return result\n",
    "\n",
    "train_dict = get_json_dict(train)\n",
    "test_dict = get_json_dict(test)\n",
    "\n",
    "# remove cateogry with bias and low frequency\n",
    "for col in json_cols :\n",
    "    \n",
    "    remove = []\n",
    "    train_id = set(list(train_dict[col].keys()))\n",
    "    test_id = set(list(test_dict[col].keys()))   \n",
    "    \n",
    "    remove += list(train_id - test_id) + list(test_id - train_id)\n",
    "    for i in train_id.union(test_id) - set(remove) :\n",
    "        if train_dict[col][i] < 10 or i == '' :\n",
    "            remove += [i]\n",
    "            \n",
    "    for i in remove :\n",
    "        if i in train_dict[col] :\n",
    "            del train_dict[col][i]\n",
    "        if i in test_dict[col] :\n",
    "            del test_dict[col][i]\n",
    "            \n",
    "all_data = prepare(pd.concat([train, test]).reset_index(drop = True))\n",
    "train = all_data.loc[:train.shape[0] - 1,:]\n",
    "test = all_data.loc[train.shape[0]:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[(np.isnan(train)) | (train==float('inf')) | (train==float('-inf'))] = 0\n",
    "test[(np.isnan(test)) | (test==float('inf')) | (test==float('-inf'))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5001, 204) (4398, 204) (5001,)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5001, 204) (5001,) (4398, 204)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "X_train = sc.fit_transform(train.values)\n",
    "y_train = y / 1000\n",
    "X_test = sc.fit_transform(test.values)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn.preprocessing as prepro\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "sc = StandardScaler()\n",
    "mm = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 1000)              205000    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 706,001\n",
      "Trainable params: 706,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1000, activation='relu', input_dim=204))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(10000, activation='relu', kernel_initializer='uniform'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1001 samples\n",
      "Epoch 1/100\n",
      "4000/4000 [==============================] - 2s 615us/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 3.4293e-04 - val_mean_squared_error: 3.4293e-04\n",
      "Epoch 2/100\n",
      "4000/4000 [==============================] - 1s 223us/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 1.3956e-04 - val_mean_squared_error: 1.3956e-04\n",
      "Epoch 3/100\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 5.8019e-04 - mean_squared_error: 5.8019e-04 - val_loss: 1.2704e-04 - val_mean_squared_error: 1.2704e-04\n",
      "Epoch 4/100\n",
      "4000/4000 [==============================] - 1s 330us/step - loss: 3.3406e-04 - mean_squared_error: 3.3406e-04 - val_loss: 1.0180e-04 - val_mean_squared_error: 1.0180e-04\n",
      "Epoch 5/100\n",
      "4000/4000 [==============================] - 1s 256us/step - loss: 2.1305e-04 - mean_squared_error: 2.1305e-04 - val_loss: 7.8159e-05 - val_mean_squared_error: 7.8159e-05\n",
      "Epoch 6/100\n",
      "4000/4000 [==============================] - 1s 239us/step - loss: 1.3521e-04 - mean_squared_error: 1.3521e-04 - val_loss: 4.9915e-05 - val_mean_squared_error: 4.9915e-05\n",
      "Epoch 7/100\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 8.3254e-05 - mean_squared_error: 8.3254e-05 - val_loss: 3.7842e-05 - val_mean_squared_error: 3.7842e-05\n",
      "Epoch 8/100\n",
      "4000/4000 [==============================] - 1s 263us/step - loss: 5.7982e-05 - mean_squared_error: 5.7982e-05 - val_loss: 2.8135e-05 - val_mean_squared_error: 2.8135e-05\n",
      "Epoch 9/100\n",
      "4000/4000 [==============================] - 1s 222us/step - loss: 4.4961e-05 - mean_squared_error: 4.4961e-05 - val_loss: 2.3597e-05 - val_mean_squared_error: 2.3597e-05\n",
      "Epoch 10/100\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 3.3785e-05 - mean_squared_error: 3.3785e-05 - val_loss: 2.0338e-05 - val_mean_squared_error: 2.0338e-05\n",
      "Epoch 11/100\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 3.0303e-05 - mean_squared_error: 3.0303e-05 - val_loss: 1.8422e-05 - val_mean_squared_error: 1.8422e-05\n",
      "Epoch 12/100\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 2.5248e-05 - mean_squared_error: 2.5248e-05 - val_loss: 1.8347e-05 - val_mean_squared_error: 1.8347e-05\n",
      "Epoch 13/100\n",
      "4000/4000 [==============================] - 1s 222us/step - loss: 2.0826e-05 - mean_squared_error: 2.0826e-05 - val_loss: 1.8761e-05 - val_mean_squared_error: 1.8761e-05\n",
      "Epoch 14/100\n",
      "4000/4000 [==============================] - 1s 220us/step - loss: 1.9294e-05 - mean_squared_error: 1.9294e-05 - val_loss: 1.7613e-05 - val_mean_squared_error: 1.7613e-05\n",
      "Epoch 15/100\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 1.7302e-05 - mean_squared_error: 1.7302e-05 - val_loss: 1.7590e-05 - val_mean_squared_error: 1.7590e-05\n",
      "Epoch 16/100\n",
      "4000/4000 [==============================] - 1s 221us/step - loss: 1.6441e-05 - mean_squared_error: 1.6441e-05 - val_loss: 1.7266e-05 - val_mean_squared_error: 1.7266e-05\n",
      "Epoch 17/100\n",
      "4000/4000 [==============================] - 1s 222us/step - loss: 1.6753e-05 - mean_squared_error: 1.6753e-05 - val_loss: 1.7455e-05 - val_mean_squared_error: 1.7455e-05\n",
      "Epoch 18/100\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 1.5004e-05 - mean_squared_error: 1.5004e-05 - val_loss: 1.7277e-05 - val_mean_squared_error: 1.7277e-05\n",
      "Epoch 19/100\n",
      "4000/4000 [==============================] - 1s 225us/step - loss: 1.5061e-05 - mean_squared_error: 1.5061e-05 - val_loss: 1.7283e-05 - val_mean_squared_error: 1.7283e-05\n",
      "Epoch 20/100\n",
      "4000/4000 [==============================] - 1s 223us/step - loss: 1.4282e-05 - mean_squared_error: 1.4282e-05 - val_loss: 1.7408e-05 - val_mean_squared_error: 1.7408e-05\n",
      "Epoch 21/100\n",
      "4000/4000 [==============================] - 1s 220us/step - loss: 1.3554e-05 - mean_squared_error: 1.3554e-05 - val_loss: 1.7335e-05 - val_mean_squared_error: 1.7335e-05\n",
      "Epoch 22/100\n",
      "4000/4000 [==============================] - 1s 224us/step - loss: 1.2996e-05 - mean_squared_error: 1.2996e-05 - val_loss: 1.7451e-05 - val_mean_squared_error: 1.7451e-05\n",
      "Epoch 23/100\n",
      "4000/4000 [==============================] - 1s 222us/step - loss: 1.3351e-05 - mean_squared_error: 1.3351e-05 - val_loss: 1.7322e-05 - val_mean_squared_error: 1.7322e-05\n",
      "Epoch 24/100\n",
      "4000/4000 [==============================] - 1s 225us/step - loss: 1.2197e-05 - mean_squared_error: 1.2197e-05 - val_loss: 1.7365e-05 - val_mean_squared_error: 1.7365e-05\n",
      "Epoch 25/100\n",
      "4000/4000 [==============================] - 1s 224us/step - loss: 1.2409e-05 - mean_squared_error: 1.2409e-05 - val_loss: 1.7459e-05 - val_mean_squared_error: 1.7459e-05\n",
      "Epoch 26/100\n",
      "4000/4000 [==============================] - 1s 225us/step - loss: 1.1595e-05 - mean_squared_error: 1.1595e-05 - val_loss: 1.7392e-05 - val_mean_squared_error: 1.7392e-05\n",
      "Epoch 27/100\n",
      "4000/4000 [==============================] - 1s 225us/step - loss: 1.1964e-05 - mean_squared_error: 1.1964e-05 - val_loss: 1.7374e-05 - val_mean_squared_error: 1.7374e-05\n",
      "Epoch 28/100\n",
      "4000/4000 [==============================] - 1s 222us/step - loss: 1.1786e-05 - mean_squared_error: 1.1786e-05 - val_loss: 1.7392e-05 - val_mean_squared_error: 1.7392e-05\n",
      "Epoch 29/100\n",
      "4000/4000 [==============================] - 1s 260us/step - loss: 1.1313e-05 - mean_squared_error: 1.1313e-05 - val_loss: 1.7404e-05 - val_mean_squared_error: 1.7404e-05\n",
      "Epoch 30/100\n",
      "4000/4000 [==============================] - 1s 247us/step - loss: 1.1808e-05 - mean_squared_error: 1.1808e-05 - val_loss: 1.7422e-05 - val_mean_squared_error: 1.7422e-05\n",
      "Epoch 31/100\n",
      "4000/4000 [==============================] - 1s 217us/step - loss: 1.0977e-05 - mean_squared_error: 1.0977e-05 - val_loss: 1.7359e-05 - val_mean_squared_error: 1.7359e-05\n",
      "Epoch 32/100\n",
      "4000/4000 [==============================] - 1s 255us/step - loss: 1.1511e-05 - mean_squared_error: 1.1511e-05 - val_loss: 1.7283e-05 - val_mean_squared_error: 1.7283e-05\n",
      "Epoch 33/100\n",
      "4000/4000 [==============================] - 1s 231us/step - loss: 1.1015e-05 - mean_squared_error: 1.1015e-05 - val_loss: 1.7328e-05 - val_mean_squared_error: 1.7328e-05\n",
      "Epoch 34/100\n",
      "4000/4000 [==============================] - 1s 220us/step - loss: 1.1098e-05 - mean_squared_error: 1.1098e-05 - val_loss: 1.7278e-05 - val_mean_squared_error: 1.7278e-05\n",
      "Epoch 35/100\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 1.0944e-05 - mean_squared_error: 1.0944e-05 - val_loss: 1.7246e-05 - val_mean_squared_error: 1.7246e-05\n",
      "Epoch 36/100\n",
      "4000/4000 [==============================] - 1s 212us/step - loss: 1.0911e-05 - mean_squared_error: 1.0911e-05 - val_loss: 1.7362e-05 - val_mean_squared_error: 1.7362e-05\n",
      "Epoch 37/100\n",
      "4000/4000 [==============================] - 1s 268us/step - loss: 1.1121e-05 - mean_squared_error: 1.1121e-05 - val_loss: 1.7281e-05 - val_mean_squared_error: 1.7281e-05\n",
      "Epoch 38/100\n",
      "4000/4000 [==============================] - 1s 251us/step - loss: 1.0500e-05 - mean_squared_error: 1.0500e-05 - val_loss: 1.7192e-05 - val_mean_squared_error: 1.7192e-05\n",
      "Epoch 39/100\n",
      "4000/4000 [==============================] - 1s 235us/step - loss: 1.1035e-05 - mean_squared_error: 1.1035e-05 - val_loss: 1.7283e-05 - val_mean_squared_error: 1.7283e-05\n",
      "Epoch 40/100\n",
      "4000/4000 [==============================] - 1s 242us/step - loss: 1.0624e-05 - mean_squared_error: 1.0624e-05 - val_loss: 1.7233e-05 - val_mean_squared_error: 1.7233e-05\n",
      "Epoch 41/100\n",
      "4000/4000 [==============================] - 1s 258us/step - loss: 1.0255e-05 - mean_squared_error: 1.0255e-05 - val_loss: 1.7417e-05 - val_mean_squared_error: 1.7417e-05\n",
      "Epoch 42/100\n",
      "4000/4000 [==============================] - 1s 251us/step - loss: 1.0536e-05 - mean_squared_error: 1.0536e-05 - val_loss: 1.7221e-05 - val_mean_squared_error: 1.7221e-05\n",
      "Epoch 43/100\n",
      "4000/4000 [==============================] - 1s 235us/step - loss: 1.0344e-05 - mean_squared_error: 1.0344e-05 - val_loss: 1.7180e-05 - val_mean_squared_error: 1.7180e-05\n",
      "Epoch 44/100\n",
      "4000/4000 [==============================] - 1s 232us/step - loss: 1.0586e-05 - mean_squared_error: 1.0586e-05 - val_loss: 1.7224e-05 - val_mean_squared_error: 1.7224e-05\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 208us/step - loss: 1.0524e-05 - mean_squared_error: 1.0524e-05 - val_loss: 1.7225e-05 - val_mean_squared_error: 1.7225e-05\n",
      "Epoch 46/100\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 1.0445e-05 - mean_squared_error: 1.0445e-05 - val_loss: 1.7044e-05 - val_mean_squared_error: 1.7044e-05\n",
      "Epoch 47/100\n",
      "4000/4000 [==============================] - 1s 247us/step - loss: 1.0296e-05 - mean_squared_error: 1.0296e-05 - val_loss: 1.7112e-05 - val_mean_squared_error: 1.7112e-05\n",
      "Epoch 48/100\n",
      "4000/4000 [==============================] - 1s 232us/step - loss: 1.0428e-05 - mean_squared_error: 1.0428e-05 - val_loss: 1.6913e-05 - val_mean_squared_error: 1.6913e-05\n",
      "Epoch 49/100\n",
      "4000/4000 [==============================] - 1s 209us/step - loss: 9.8706e-06 - mean_squared_error: 9.8706e-06 - val_loss: 1.6941e-05 - val_mean_squared_error: 1.6941e-05\n",
      "Epoch 50/100\n",
      "4000/4000 [==============================] - 1s 218us/step - loss: 9.8139e-06 - mean_squared_error: 9.8139e-06 - val_loss: 1.6852e-05 - val_mean_squared_error: 1.6852e-05\n",
      "Epoch 51/100\n",
      "4000/4000 [==============================] - 1s 242us/step - loss: 9.7601e-06 - mean_squared_error: 9.7601e-06 - val_loss: 1.6993e-05 - val_mean_squared_error: 1.6993e-05\n",
      "Epoch 52/100\n",
      "4000/4000 [==============================] - 1s 250us/step - loss: 9.8646e-06 - mean_squared_error: 9.8646e-06 - val_loss: 1.6922e-05 - val_mean_squared_error: 1.6922e-05\n",
      "Epoch 53/100\n",
      "4000/4000 [==============================] - 1s 250us/step - loss: 9.8324e-06 - mean_squared_error: 9.8324e-06 - val_loss: 1.6878e-05 - val_mean_squared_error: 1.6878e-05\n",
      "Epoch 54/100\n",
      "4000/4000 [==============================] - 1s 245us/step - loss: 9.6703e-06 - mean_squared_error: 9.6703e-06 - val_loss: 1.6944e-05 - val_mean_squared_error: 1.6944e-05\n",
      "Epoch 55/100\n",
      "4000/4000 [==============================] - 1s 216us/step - loss: 9.7349e-06 - mean_squared_error: 9.7349e-06 - val_loss: 1.6853e-05 - val_mean_squared_error: 1.6853e-05\n",
      "Epoch 56/100\n",
      "4000/4000 [==============================] - 1s 211us/step - loss: 9.6293e-06 - mean_squared_error: 9.6293e-06 - val_loss: 1.6914e-05 - val_mean_squared_error: 1.6914e-05\n",
      "Epoch 57/100\n",
      "4000/4000 [==============================] - 1s 213us/step - loss: 9.3487e-06 - mean_squared_error: 9.3487e-06 - val_loss: 1.6914e-05 - val_mean_squared_error: 1.6914e-05\n",
      "Epoch 58/100\n",
      "4000/4000 [==============================] - 1s 289us/step - loss: 9.2493e-06 - mean_squared_error: 9.2493e-06 - val_loss: 1.6795e-05 - val_mean_squared_error: 1.6795e-05\n",
      "Epoch 59/100\n",
      "4000/4000 [==============================] - 1s 239us/step - loss: 9.2007e-06 - mean_squared_error: 9.2007e-06 - val_loss: 1.6809e-05 - val_mean_squared_error: 1.6809e-05\n",
      "Epoch 60/100\n",
      "4000/4000 [==============================] - 1s 250us/step - loss: 9.2478e-06 - mean_squared_error: 9.2478e-06 - val_loss: 1.6702e-05 - val_mean_squared_error: 1.6702e-05\n",
      "Epoch 61/100\n",
      "4000/4000 [==============================] - 1s 269us/step - loss: 9.1500e-06 - mean_squared_error: 9.1500e-06 - val_loss: 1.6699e-05 - val_mean_squared_error: 1.6699e-05\n",
      "Epoch 62/100\n",
      "4000/4000 [==============================] - 1s 256us/step - loss: 9.3591e-06 - mean_squared_error: 9.3591e-06 - val_loss: 1.6738e-05 - val_mean_squared_error: 1.6738e-05\n",
      "Epoch 63/100\n",
      "4000/4000 [==============================] - 1s 283us/step - loss: 9.3588e-06 - mean_squared_error: 9.3588e-06 - val_loss: 1.6706e-05 - val_mean_squared_error: 1.6706e-05\n",
      "Epoch 64/100\n",
      "4000/4000 [==============================] - 2s 409us/step - loss: 9.1427e-06 - mean_squared_error: 9.1427e-06 - val_loss: 1.6716e-05 - val_mean_squared_error: 1.6716e-05\n",
      "Epoch 65/100\n",
      "4000/4000 [==============================] - 2s 423us/step - loss: 9.3170e-06 - mean_squared_error: 9.3170e-06 - val_loss: 1.6704e-05 - val_mean_squared_error: 1.6704e-05\n",
      "Epoch 66/100\n",
      "4000/4000 [==============================] - 1s 351us/step - loss: 9.0622e-06 - mean_squared_error: 9.0622e-06 - val_loss: 1.6760e-05 - val_mean_squared_error: 1.6760e-05\n",
      "Epoch 67/100\n",
      "4000/4000 [==============================] - 1s 349us/step - loss: 9.1355e-06 - mean_squared_error: 9.1355e-06 - val_loss: 1.6674e-05 - val_mean_squared_error: 1.6674e-05\n",
      "Epoch 68/100\n",
      "4000/4000 [==============================] - 1s 349us/step - loss: 9.2270e-06 - mean_squared_error: 9.2270e-06 - val_loss: 1.6716e-05 - val_mean_squared_error: 1.6716e-05\n",
      "Epoch 69/100\n",
      "4000/4000 [==============================] - 1s 359us/step - loss: 9.2273e-06 - mean_squared_error: 9.2273e-06 - val_loss: 1.6841e-05 - val_mean_squared_error: 1.6841e-05\n",
      "Epoch 70/100\n",
      "4000/4000 [==============================] - 1s 349us/step - loss: 9.0238e-06 - mean_squared_error: 9.0238e-06 - val_loss: 1.6754e-05 - val_mean_squared_error: 1.6754e-05\n",
      "Epoch 71/100\n",
      "4000/4000 [==============================] - 2s 403us/step - loss: 9.1584e-06 - mean_squared_error: 9.1584e-06 - val_loss: 1.6710e-05 - val_mean_squared_error: 1.6710e-05\n",
      "Epoch 72/100\n",
      "4000/4000 [==============================] - 2s 400us/step - loss: 9.1120e-06 - mean_squared_error: 9.1120e-06 - val_loss: 1.6574e-05 - val_mean_squared_error: 1.6574e-05\n",
      "Epoch 73/100\n",
      "4000/4000 [==============================] - 1s 358us/step - loss: 8.9005e-06 - mean_squared_error: 8.9005e-06 - val_loss: 1.6605e-05 - val_mean_squared_error: 1.6605e-05\n",
      "Epoch 74/100\n",
      "4000/4000 [==============================] - 1s 355us/step - loss: 8.8330e-06 - mean_squared_error: 8.8330e-06 - val_loss: 1.6561e-05 - val_mean_squared_error: 1.6561e-05\n",
      "Epoch 75/100\n",
      "4000/4000 [==============================] - 1s 361us/step - loss: 9.1010e-06 - mean_squared_error: 9.1010e-06 - val_loss: 1.6605e-05 - val_mean_squared_error: 1.6605e-05\n",
      "Epoch 76/100\n",
      "4000/4000 [==============================] - 1s 359us/step - loss: 8.8137e-06 - mean_squared_error: 8.8137e-06 - val_loss: 1.6643e-05 - val_mean_squared_error: 1.6643e-05\n",
      "Epoch 77/100\n",
      "4000/4000 [==============================] - 1s 363us/step - loss: 8.6634e-06 - mean_squared_error: 8.6634e-06 - val_loss: 1.6430e-05 - val_mean_squared_error: 1.6430e-05\n",
      "Epoch 78/100\n",
      "4000/4000 [==============================] - 1s 349us/step - loss: 9.0676e-06 - mean_squared_error: 9.0676e-06 - val_loss: 1.6500e-05 - val_mean_squared_error: 1.6500e-05\n",
      "Epoch 79/100\n",
      "4000/4000 [==============================] - 1s 365us/step - loss: 8.9331e-06 - mean_squared_error: 8.9331e-06 - val_loss: 1.6495e-05 - val_mean_squared_error: 1.6495e-05\n",
      "Epoch 80/100\n",
      "4000/4000 [==============================] - 1s 359us/step - loss: 8.9198e-06 - mean_squared_error: 8.9198e-06 - val_loss: 1.6733e-05 - val_mean_squared_error: 1.6733e-05\n",
      "Epoch 81/100\n",
      "4000/4000 [==============================] - 1s 368us/step - loss: 8.9127e-06 - mean_squared_error: 8.9127e-06 - val_loss: 1.6406e-05 - val_mean_squared_error: 1.6406e-05\n",
      "Epoch 82/100\n",
      "4000/4000 [==============================] - 1s 372us/step - loss: 8.7567e-06 - mean_squared_error: 8.7567e-06 - val_loss: 1.6363e-05 - val_mean_squared_error: 1.6363e-05\n",
      "Epoch 83/100\n",
      "4000/4000 [==============================] - 1s 362us/step - loss: 8.8355e-06 - mean_squared_error: 8.8355e-06 - val_loss: 1.6373e-05 - val_mean_squared_error: 1.6373e-05\n",
      "Epoch 84/100\n",
      "4000/4000 [==============================] - 1s 368us/step - loss: 8.7979e-06 - mean_squared_error: 8.7979e-06 - val_loss: 1.6325e-05 - val_mean_squared_error: 1.6325e-05\n",
      "Epoch 85/100\n",
      "4000/4000 [==============================] - 1s 370us/step - loss: 8.5665e-06 - mean_squared_error: 8.5665e-06 - val_loss: 1.6271e-05 - val_mean_squared_error: 1.6271e-05\n",
      "Epoch 86/100\n",
      "4000/4000 [==============================] - 2s 388us/step - loss: 8.6871e-06 - mean_squared_error: 8.6871e-06 - val_loss: 1.6307e-05 - val_mean_squared_error: 1.6307e-05\n",
      "Epoch 87/100\n",
      "4000/4000 [==============================] - 2s 397us/step - loss: 9.1088e-06 - mean_squared_error: 9.1088e-06 - val_loss: 1.6357e-05 - val_mean_squared_error: 1.6357e-05\n",
      "Epoch 88/100\n",
      "4000/4000 [==============================] - 1s 243us/step - loss: 8.8341e-06 - mean_squared_error: 8.8341e-06 - val_loss: 1.6321e-05 - val_mean_squared_error: 1.6321e-05\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 214us/step - loss: 8.9455e-06 - mean_squared_error: 8.9455e-06 - val_loss: 1.6416e-05 - val_mean_squared_error: 1.6416e-05\n",
      "Epoch 90/100\n",
      "4000/4000 [==============================] - 1s 233us/step - loss: 8.7077e-06 - mean_squared_error: 8.7077e-06 - val_loss: 1.6273e-05 - val_mean_squared_error: 1.6273e-05\n",
      "Epoch 91/100\n",
      "4000/4000 [==============================] - 1s 219us/step - loss: 8.6533e-06 - mean_squared_error: 8.6533e-06 - val_loss: 1.6246e-05 - val_mean_squared_error: 1.6246e-05\n",
      "Epoch 92/100\n",
      "4000/4000 [==============================] - 1s 201us/step - loss: 8.4989e-06 - mean_squared_error: 8.4989e-06 - val_loss: 1.6304e-05 - val_mean_squared_error: 1.6304e-05\n",
      "Epoch 93/100\n",
      "4000/4000 [==============================] - 1s 202us/step - loss: 8.5407e-06 - mean_squared_error: 8.5407e-06 - val_loss: 1.6258e-05 - val_mean_squared_error: 1.6258e-05\n",
      "Epoch 94/100\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 8.4818e-06 - mean_squared_error: 8.4818e-06 - val_loss: 1.6232e-05 - val_mean_squared_error: 1.6232e-05\n",
      "Epoch 95/100\n",
      "4000/4000 [==============================] - 1s 204us/step - loss: 8.3970e-06 - mean_squared_error: 8.3970e-06 - val_loss: 1.6111e-05 - val_mean_squared_error: 1.6111e-05\n",
      "Epoch 96/100\n",
      "4000/4000 [==============================] - 1s 234us/step - loss: 8.4069e-06 - mean_squared_error: 8.4069e-06 - val_loss: 1.6078e-05 - val_mean_squared_error: 1.6078e-05\n",
      "Epoch 97/100\n",
      "4000/4000 [==============================] - 1s 224us/step - loss: 8.4262e-06 - mean_squared_error: 8.4262e-06 - val_loss: 1.6163e-05 - val_mean_squared_error: 1.6163e-05\n",
      "Epoch 98/100\n",
      "4000/4000 [==============================] - 1s 225us/step - loss: 8.1659e-06 - mean_squared_error: 8.1659e-06 - val_loss: 1.6073e-05 - val_mean_squared_error: 1.6073e-05\n",
      "Epoch 99/100\n",
      "4000/4000 [==============================] - 1s 223us/step - loss: 8.5242e-06 - mean_squared_error: 8.5242e-06 - val_loss: 1.6047e-05 - val_mean_squared_error: 1.6047e-05\n",
      "Epoch 100/100\n",
      "4000/4000 [==============================] - 1s 255us/step - loss: 8.5615e-06 - mean_squared_error: 8.5615e-06 - val_loss: 1.6260e-05 - val_mean_squared_error: 1.6260e-05\n",
      "dict_keys(['val_loss', 'val_mean_squared_error', 'loss', 'mean_squared_error'])\n",
      "5001/5001 [==============================] - 1s 186us/step\n",
      "mean_squared_error: 0.00%\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss='mse', metrics=['mse'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=100, validation_split=0.2, verbose=1, shuffle=True)\n",
    "print(history.history.keys())\n",
    "\n",
    "scores = model.evaluate(X_train, y_train, batch_size=30)\n",
    "print('%s: %.2f%%' % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.read_csv('../data/movie/test.csv')\n",
    "df_out['revenue'] = np.expm1(predict*1000)\n",
    "df_out[['id', 'revenue']].to_csv(\"../data/movie/output/k_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4.166826e+06\n",
       "1       2.646025e+06\n",
       "2       2.351236e+06\n",
       "3       4.135006e+06\n",
       "4       3.294134e+06\n",
       "5       6.655230e+05\n",
       "6       4.183027e+05\n",
       "7       3.988027e+07\n",
       "8       8.156569e+06\n",
       "9       1.369793e+09\n",
       "10      2.801425e+06\n",
       "11      3.764718e+05\n",
       "12      6.642048e+06\n",
       "13      3.237813e+06\n",
       "14      2.655773e+07\n",
       "15      5.440491e+05\n",
       "16      4.609300e+07\n",
       "17      4.609141e+07\n",
       "18      1.748343e+06\n",
       "19      6.931353e+09\n",
       "20      1.422683e+07\n",
       "21      2.954901e+07\n",
       "22      4.426977e+05\n",
       "23      8.361591e+06\n",
       "24      6.205444e+05\n",
       "25      6.656599e+07\n",
       "26      1.708337e+07\n",
       "27      6.180006e+07\n",
       "28      1.189452e+06\n",
       "29      7.507050e+06\n",
       "            ...     \n",
       "4368    4.566301e+06\n",
       "4369    2.232890e+07\n",
       "4370    5.324273e+05\n",
       "4371    1.576236e+07\n",
       "4372    4.200685e+08\n",
       "4373    1.226960e+07\n",
       "4374    2.320816e+07\n",
       "4375    3.481486e+05\n",
       "4376    9.895244e+06\n",
       "4377    1.623386e+07\n",
       "4378    7.848780e+06\n",
       "4379    2.212750e+06\n",
       "4380    1.650719e+06\n",
       "4381    8.270065e+06\n",
       "4382    1.158816e+06\n",
       "4383    8.261654e+06\n",
       "4384    1.542541e+07\n",
       "4385    3.287828e+07\n",
       "4386    6.423937e+05\n",
       "4387    4.605190e+05\n",
       "4388    1.962245e+06\n",
       "4389    3.441847e+05\n",
       "4390    6.683961e+05\n",
       "4391    7.535626e+06\n",
       "4392    7.654588e+08\n",
       "4393    1.470884e+07\n",
       "4394    1.075485e+08\n",
       "4395    1.388468e+07\n",
       "4396    8.569371e+06\n",
       "4397    8.315907e+05\n",
       "Name: revenue, Length: 4398, dtype: float32"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
